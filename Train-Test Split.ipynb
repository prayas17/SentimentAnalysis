{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa26b87c-d8d7-44aa-9574-ff9227a9db85",
   "metadata": {},
   "source": [
    "### Here doing Data cleaning and pre processing directly because I have done it clearly and seperately line by line in \n",
    "### DataCleaning and EDA Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893a4533-2ae7-4243-8829-50ab7b307a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Prayas\n",
      "[nltk_data]     jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Prayas\n",
      "[nltk_data]     jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Prayas\n",
      "[nltk_data]     jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Function for preprocessing text data\n",
    "def preprocess_text(df, text_column):\n",
    "    # Lowercase the text\n",
    "    df[text_column] = df[text_column].str.lower()\n",
    "    \n",
    "    # Remove special characters, punctuation, and symbols\n",
    "    def remove_special_characters(text):\n",
    "        pattern = r'[^a-zA-Z0-9\\s]'  # Define regex pattern\n",
    "        return re.sub(pattern, '', text)\n",
    "    \n",
    "    df[text_column] = df[text_column].apply(remove_special_characters)\n",
    "    \n",
    "    # Remove numbers\n",
    "    def remove_numbers(text):\n",
    "        pattern = r'\\b\\d+\\b'  # Define regex pattern to match any standalone number\n",
    "        return re.sub(pattern, '', text)\n",
    "    \n",
    "    df[text_column] = df[text_column].apply(remove_numbers)\n",
    "    \n",
    "    # Download stopwords list\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stopwords\n",
    "    def remove_stopwords(text):\n",
    "        cleaned_text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        return cleaned_text\n",
    "    \n",
    "    df[text_column] = df[text_column].apply(remove_stopwords)\n",
    "    \n",
    "    # Tokenize text\n",
    "    nltk.download('punkt')\n",
    "    def tokenize_text(text):\n",
    "        return word_tokenize(text)\n",
    "    \n",
    "    df['token'] = df[text_column].apply(tokenize_text)\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    def stem_tokens(tokens):\n",
    "        stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "        return stemmed_tokens\n",
    "    \n",
    "    df['stemmed_token'] = df['token'].apply(stem_tokens)\n",
    "    \n",
    "    # Lemmatization\n",
    "    nltk.download('wordnet')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_tokens(tokens):\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        return lemmatized_tokens\n",
    "    \n",
    "    df['lemmatized_token'] = df['stemmed_token'].apply(lemmatize_tokens)\n",
    "    \n",
    "    # Combine tokens into cleaned text\n",
    "    df['cleaned_text'] = df['lemmatized_token'].apply(lambda tokens: ' '.join(tokens))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"hate.csv\" , encoding='latin1')  \n",
    "\n",
    "# Preprocess text data\n",
    "data = preprocess_text(data, 'comment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5fa09-1ae6-4aac-b189-0287a8b6b7cb",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aae5594-0c11-460c-be02-6c840048e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>token</th>\n",
       "      <th>stemmed_token</th>\n",
       "      <th>lemmatized_token</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dalits lowlives</td>\n",
       "      <td>N</td>\n",
       "      <td>[dalits, lowlives]</td>\n",
       "      <td>[dalit, lowliv]</td>\n",
       "      <td>[dalit, lowliv]</td>\n",
       "      <td>dalit lowliv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gay people burden society</td>\n",
       "      <td>N</td>\n",
       "      <td>[gay, people, burden, society]</td>\n",
       "      <td>[gay, peopl, burden, societi]</td>\n",
       "      <td>[gay, peopl, burden, societi]</td>\n",
       "      <td>gay peopl burden societi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>arabs welcome</td>\n",
       "      <td>N</td>\n",
       "      <td>[arabs, welcome]</td>\n",
       "      <td>[arab, welcom]</td>\n",
       "      <td>[arab, welcom]</td>\n",
       "      <td>arab welcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>im saying actually eliminate heebs wish natura...</td>\n",
       "      <td>N</td>\n",
       "      <td>[im, saying, actually, eliminate, heebs, wish,...</td>\n",
       "      <td>[im, say, actual, elimin, heeb, wish, natur, b...</td>\n",
       "      <td>[im, say, actual, elimin, heeb, wish, natur, b...</td>\n",
       "      <td>im say actual elimin heeb wish natur becam ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bananas black people</td>\n",
       "      <td>N</td>\n",
       "      <td>[bananas, black, people]</td>\n",
       "      <td>[banana, black, peopl]</td>\n",
       "      <td>[banana, black, peopl]</td>\n",
       "      <td>banana black peopl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>117100</td>\n",
       "      <td>indian culture backwards</td>\n",
       "      <td>N</td>\n",
       "      <td>[indian, culture, backwards]</td>\n",
       "      <td>[indian, cultur, backward]</td>\n",
       "      <td>[indian, cultur, backward]</td>\n",
       "      <td>indian cultur backward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>118100</td>\n",
       "      <td>women dont want equality want charge</td>\n",
       "      <td>N</td>\n",
       "      <td>[women, dont, want, equality, want, charge]</td>\n",
       "      <td>[women, dont, want, equal, want, charg]</td>\n",
       "      <td>[woman, dont, want, equal, want, charg]</td>\n",
       "      <td>woman dont want equal want charg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41141</th>\n",
       "      <td>119100</td>\n",
       "      <td>fuck covid</td>\n",
       "      <td>P</td>\n",
       "      <td>[fuck, covid]</td>\n",
       "      <td>[fuck, covid]</td>\n",
       "      <td>[fuck, covid]</td>\n",
       "      <td>fuck covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41142</th>\n",
       "      <td>1205</td>\n",
       "      <td>computer garbage</td>\n",
       "      <td>P</td>\n",
       "      <td>[computer, garbage]</td>\n",
       "      <td>[comput, garbag]</td>\n",
       "      <td>[comput, garbag]</td>\n",
       "      <td>comput garbag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>121100</td>\n",
       "      <td>good muslim dead one</td>\n",
       "      <td>N</td>\n",
       "      <td>[good, muslim, dead, one]</td>\n",
       "      <td>[good, muslim, dead, one]</td>\n",
       "      <td>[good, muslim, dead, one]</td>\n",
       "      <td>good muslim dead one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41144 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            comment label  \\\n",
       "0               1                                    dalits lowlives     N   \n",
       "1               2                          gay people burden society     N   \n",
       "2               3                                      arabs welcome     N   \n",
       "3               4  im saying actually eliminate heebs wish natura...     N   \n",
       "4               5                               bananas black people     N   \n",
       "...           ...                                                ...   ...   \n",
       "41139      117100                           indian culture backwards     N   \n",
       "41140      118100               women dont want equality want charge     N   \n",
       "41141      119100                                         fuck covid     P   \n",
       "41142        1205                                   computer garbage     P   \n",
       "41143      121100                               good muslim dead one     N   \n",
       "\n",
       "                                                   token  \\\n",
       "0                                     [dalits, lowlives]   \n",
       "1                         [gay, people, burden, society]   \n",
       "2                                       [arabs, welcome]   \n",
       "3      [im, saying, actually, eliminate, heebs, wish,...   \n",
       "4                               [bananas, black, people]   \n",
       "...                                                  ...   \n",
       "41139                       [indian, culture, backwards]   \n",
       "41140        [women, dont, want, equality, want, charge]   \n",
       "41141                                      [fuck, covid]   \n",
       "41142                                [computer, garbage]   \n",
       "41143                          [good, muslim, dead, one]   \n",
       "\n",
       "                                           stemmed_token  \\\n",
       "0                                        [dalit, lowliv]   \n",
       "1                          [gay, peopl, burden, societi]   \n",
       "2                                         [arab, welcom]   \n",
       "3      [im, say, actual, elimin, heeb, wish, natur, b...   \n",
       "4                                 [banana, black, peopl]   \n",
       "...                                                  ...   \n",
       "41139                         [indian, cultur, backward]   \n",
       "41140            [women, dont, want, equal, want, charg]   \n",
       "41141                                      [fuck, covid]   \n",
       "41142                                   [comput, garbag]   \n",
       "41143                          [good, muslim, dead, one]   \n",
       "\n",
       "                                        lemmatized_token  \\\n",
       "0                                        [dalit, lowliv]   \n",
       "1                          [gay, peopl, burden, societi]   \n",
       "2                                         [arab, welcom]   \n",
       "3      [im, say, actual, elimin, heeb, wish, natur, b...   \n",
       "4                                 [banana, black, peopl]   \n",
       "...                                                  ...   \n",
       "41139                         [indian, cultur, backward]   \n",
       "41140            [woman, dont, want, equal, want, charg]   \n",
       "41141                                      [fuck, covid]   \n",
       "41142                                   [comput, garbag]   \n",
       "41143                          [good, muslim, dead, one]   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0                                           dalit lowliv  \n",
       "1                               gay peopl burden societi  \n",
       "2                                            arab welcom  \n",
       "3      im say actual elimin heeb wish natur becam ext...  \n",
       "4                                     banana black peopl  \n",
       "...                                                  ...  \n",
       "41139                             indian cultur backward  \n",
       "41140                   woman dont want equal want charg  \n",
       "41141                                         fuck covid  \n",
       "41142                                      comput garbag  \n",
       "41143                               good muslim dead one  \n",
       "\n",
       "[41144 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c39db5a-c8e0-4468-9041-f913a09e8f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32915,)\n",
      "X_test shape: (8229,)\n",
      "y_train shape: (32915,)\n",
      "y_test shape: (8229,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into input (X) and output (y) features\n",
    "X = data['cleaned_text']\n",
    "y = data['label']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
